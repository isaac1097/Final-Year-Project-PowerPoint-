{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbd23a2-518c-4218-a319-3d2c49b96e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the line number you want to process:  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text: to save your slide as a JPEG file just\n",
      "go to file and then go to save as and\n",
      "then browse the place where you want to\n",
      "save I'm gonna save it on my desktop\n",
      "then name your file the one you want\n",
      "then save at Skype go to jpg file change\n",
      "format and hit save and you have two\n",
      "options\n",
      "if you hit just this one you will have\n",
      "just one picture and if you connect all\n",
      "slides you all your slides will be\n",
      "turned into jfo files into a single\n",
      "folder I'm gonna hit just this one and\n",
      "my file will be turned into a jpg file\n",
      "and that's it turn your file slide into\n",
      "a JPEG format thanks for watching if you\n",
      "liked this video don't forget to hit the\n",
      "subscribe button and there will be one\n",
      "new video every Friday so don't beat the\n",
      "subscribe button so that you can get a\n",
      "new video every Friday and become a\n",
      "PowerPoint pro Thanks so what\n",
      "Intention: to save your slide as a JPEG file\n",
      "Procedure: go to file and then go to save as and then browse the place where you want to save\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "tokenizer_intention = T5Tokenizer.from_pretrained(\"google/flan-t5-large\") \n",
    "model_intention = T5ForConditionalGeneration.from_pretrained(\"Models and Results/Seeded Models/T5LargeIntention/checkpoint-444\")\n",
    "\n",
    "tokenizer_procedure = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model_procedure = T5ForConditionalGeneration.from_pretrained(\"Models and Results/Seeded Models/FlanT5LargeProcedure (Real World Diff)/checkpoint-432\")\n",
    "\n",
    "\n",
    "def generate_intention(text):\n",
    "    input_ids = tokenizer_intention.encode(\"intention: \" + text, return_tensors=\"pt\")\n",
    "    output = model_intention.generate(input_ids)\n",
    "    return tokenizer_intention.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def generate_procedure(raw_text, intention):\n",
    "    input_text = f\"Generate a procedure based on the text: {raw_text} and the intention: {intention}\"\n",
    "    input_ids = tokenizer_procedure.encode(input_text, return_tensors=\"pt\")\n",
    "    output = model_procedure.generate(input_ids)\n",
    "    return tokenizer_procedure.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "data = load_json('Models and Results/Seeded Models/FlanT5LargeProcedure (Real World Diff)/Procedure_Predictions(432).json')  \n",
    "\n",
    "line_number = int(input(\"Enter the line number you want to process: \")) - 1  \n",
    "\n",
    "if 0 <= line_number < len(data):\n",
    "    item = data[line_number]\n",
    "    raw_text = item['raw_text']  \n",
    "    intention = item['intention']  \n",
    "    procedure = generate_procedure(raw_text, intention)  \n",
    "\n",
    "    print(f\"Raw Text: {raw_text}\")\n",
    "    print(f\"Intention: {intention}\")\n",
    "    print(f\"Procedure: {procedure}\")\n",
    "else:\n",
    "    print(f\"Invalid line number. Please enter a number between 1 and {len(data)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b93c03-fd88-4fb1-9b83-100644e8cabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
